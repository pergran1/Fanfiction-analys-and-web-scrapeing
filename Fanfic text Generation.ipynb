{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 =  pd.read_csv(\"STOR_FANFIC_1000000_1086000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laddar serien som en äkta serie\n",
    "#author =  pd.read_csv(\"Series_fanfic\", squeeze=True)\n",
    "\n",
    "#EXPLICIT_Test_serie\n",
    "author =  pd.read_csv(\"EXPLICIT_Test_serie\", squeeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kommer här ifrån kolla nedan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/ab971631/beginners-guide-to-text-generation-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparar engelska och gör det till en serie med bara texten\n",
    "#df1 = df1[df1[\"language\"] == \"English\"]\n",
    "#fan_text = df1[\"story\"]\n",
    "#export_csv = fan_text.to_csv (r'C:\\\\Users\\\\GTSA - Infinity\\\\Desktop\\Series_fanfic', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lista' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-47aabe866026>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlista\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'lista' is not defined"
     ]
    }
   ],
   "source": [
    "lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       \\n\\nChapter Text\\n\\n\\nseeing somi made jooe so...\n",
       "1       \\n\\nChapter Text\\n\\n\\nHello! I am doing reques...\n",
       "2       \\n\\nChapter Text\\n\\n\\nI Don't really see any f...\n",
       "3       \\n\\nChapter Text\\n\\n\\nAxe to the face.\\n \\nTha...\n",
       "4       \\n\\nChapter Text\\n\\n\\n\\n\\n\\n\\n\\n\\nGoddessVicky...\n",
       "                              ...                        \n",
       "2047    \\n\\nPink Ribbon\\n\\n\\n\\n\\n\\n\\nvioletnudewoman\\n...\n",
       "2048    \\n\\nChapter Text\\n\\n\\nI’ll keep this simple:\\n...\n",
       "2049    \\n\\nChapter Text\\n\\n\\nBlaine hated movie theat...\n",
       "2050    They weren’t ten miles from the asylum when Ch...\n",
       "2051                     \\n\\nChapter Text\\n\\n\\n\\n\\n\\n\\n\\n\n",
       "Name: story, Length: 2052, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import string\n",
    "import unidecode\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU!\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU!')\n",
    "else: \n",
    "    print('No GPU available, training on CPU; consider making n_epochs very small.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22098"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = list(author[:100])\n",
    "def joinStrings(text):\n",
    "    return ' '.join(string for string in text)\n",
    "text = joinStrings(text)\n",
    "# text = [item for sublist in author[:5].values for item in sublist]\n",
    "len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(nltk.corpus.stopwords.words('english'))\n",
    "exclude = set(string.punctuation) \n",
    "lemma = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "def clean(doc):\n",
    "        stop_free = \" \".join([i for i in doc.split() if i not in stop])\n",
    "        punc_free = \"\".join(ch for ch in stop_free if ch not in exclude)\n",
    "        normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "        return normalized\n",
    "test_sentence = clean(text).lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['chapter', 'text'], 'seeing'), (['text', 'seeing'], 'somi'), (['seeing', 'somi'], 'made')]\n"
     ]
    }
   ],
   "source": [
    "trigrams = [([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2])\n",
    "            for i in range(len(test_sentence) - 2)]\n",
    "chunk_len=len(trigrams)\n",
    "print(trigrams[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(test_sentence)\n",
    "voc_len=len(vocab)\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp=[]\n",
    "tar=[]\n",
    "for context, target in trigrams:\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "        inp.append(context_idxs)\n",
    "        targ = torch.tensor([word_to_ix[target]], dtype=torch.long)\n",
    "        tar.append(targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size*2, hidden_size, n_layers,batch_first=True,\n",
    "                          bidirectional=False)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        input = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(inp, target):\n",
    "    hidden = decoder.init_hidden().cuda()\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    for c in range(chunk_len):\n",
    "        output, hidden = decoder(inp[c].cuda(), hidden)\n",
    "        loss += criterion(output, target[c].cuda())\n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data.item() / chunk_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, math\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43m 8s (100 16%) 0.0033]\n",
      "[86m 1s (200 33%) 0.0024]\n",
      "[129m 49s (300 50%) 0.0021]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 300\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "hidden_size = 100\n",
    "n_layers = 1\n",
    "lr = 0.015\n",
    "\n",
    "decoder = RNN(voc_len, hidden_size, voc_len, n_layers)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "if(train_on_gpu):\n",
    "    decoder.cuda()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(inp,tar)       \n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 50, loss))\n",
    "#         print(evaluate('ge', 200), '\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d5096e0088>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate(prime_str='this process', predict_len=100, temperature=0.8):\n",
    "    hidden = decoder.init_hidden().cuda()\n",
    "\n",
    "    for p in range(predict_len):\n",
    "        \n",
    "        prime_input = torch.tensor([word_to_ix[w] for w in prime_str.split()], dtype=torch.long).cuda()\n",
    "        inp = prime_input[-2:] #last two words as input\n",
    "        output, hidden = decoder(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted word to string and use as next input\n",
    "        predicted_word = list(word_to_ix.keys())[list(word_to_ix.values()).index(top_i)]\n",
    "        prime_str += \" \" + predicted_word\n",
    "#         inp = torch.tensor(word_to_ix[predicted_word], dtype=torch.long)\n",
    "\n",
    "    return prime_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this process gabriels let i help people that winwin you tilted head aside smiled bertholdt groaned looked lover arm tied head leg opened spreader bar youve little shit today slut brat like that looks like master gonna fuck sense you all able\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('this process', 40, temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love you think ive bit depressed while though as in couple year so many story sit unfinished podfic agh i let sit moldering year i make deal it even though i love\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('love you', 30, temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-4e1243bd22c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
